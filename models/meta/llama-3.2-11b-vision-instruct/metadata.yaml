apiVersion: model.hydra.io/v1alpha1
kind: ModelSpec
metadata:
  name: llama-3.2-11b-vision-instruct
spec:
  deployments:
  - customRuntimeArgs:
    - --max-model-len=4096
    - --max-num-seqs=16
    - --enforce-eager
    resourceRequirements:
      cpu: 1
      gpuCount: 1
      gpuType: vgpu
      memory: 16
      perGPUMemoryGB: 50
    runtime: vllm
    versionRequired: '>=v0.6.5'
  descriptor:
    description:
      enUS: An 11B parameter vision-instruct model from the Llama series, integrating
        vision and language processing capabilities for multimodal tasks.
      zhCN: Llama 系列的 11B 参数视觉指令模型，结合视觉和语言处理能力，适用于多模态任务。
    display: Llama-3.2-11B-Vision-Instruct
    icon:
      src: https://public-resources.d.run/models/logos/llama-model-logo.svg
      type: image/svg
    links:
    - description: About
      url: https://ai.meta.com/llama/
    provider:
      id: meta
      name:
        enUS: Meta
        zhCN: Meta
    tags:
    - TEXT_GENERATION
    - IMAGE_TO_TEXT
  source:
    huggingface:
      name: meta-llama/Llama-3.2-11B-Vision-Instruct
    modelscope:
      name: LLM-Research/Llama-3.2-11B-Vision-Instruct
